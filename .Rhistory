d = read.csv("https://sites.ecmwf.int/data/climatepulse/data/series/era5_daily_series_2t_global.csv")
d
d = read.csv(
"https://sites.ecmwf.int/data/climatepulse/data/series/era5_daily_series_2t_global.csv",
skip = 10
)
d
d = read.csv(
"https://sites.ecmwf.int/data/climatepulse/data/series/era5_daily_series_2t_global.csv",
skip = 11
)
d
d = read.csv(
"https://sites.ecmwf.int/data/climatepulse/data/series/era5_daily_series_2t_global.csv",
skip = 18
)
d
# Generate a sequence of display dates for the year 2000
display_dates <- seq(as.Date("2000-01-01"), as.Date("2000-12-31"), by = "day")
# Extract unique years from the original data
data$year <- format(data$date, "%Y")
data = read.csv(
"https://sites.ecmwf.int/data/climatepulse/data/series/era5_daily_series_2t_global.csv",
skip = 18
)
data
data %>% head
head(data)
# Generate a sequence of display dates for the year 2000
display_dates <- seq(as.Date("2000-01-01"), as.Date("2000-12-31"), by = "day")
# Extract unique years from the original data
data$year <- format(data$date, "%Y")
data$date
# Extract unique years from the original data
data$year <- format(as.Date(data$date), "%Y")
data
unique_years <- unique(data$year)
unique_years
# Create an empty data frame for the result
result <- data.frame(display_date = display_dates)
result
year = unique_years[[1]]
year
# Subset the data for the current year
year_data <- data[data$year == year, ]
year_data
data.frame(
display_date = display_dates,
day = format(display_dates, "%j")
)
display_dates
format(display_dates, "%j"()
format(display_dates, "%j")
# Generate a sequence of display dates for the year 2000
display_dates <- seq(as.Date("2000-01-01"), as.Date("2000-12-31"), by = "day")
display_keys <- format(display_dates, "%m_%d")  # Use month_dayInMonth format
display_keys
# Extract unique years from the original data
data$year <- format(data$date, "%Y")
# Extract unique years from the original data
data$year <- format(as.Date(data$date), "%Y")
data$key <- format(as.Date(data$date), "%m_%d")  # Add a key for month_dayInMonth
data
unique_years <- unique(data$year)
# Create an empty data frame for the result
result <- data.frame(display_date = display_dates)
year
# Subset the data for the current year
year_data <- data[data$year == year, ]
year_data
data.frame(
display_key = display_keys,
display_date = display_dates
)
year_data$key
# Create an empty data frame for the result
result = data.frame(display_date = display_dates)
# Loop through each year and add its `ano_91.20` column to the result
for (year in unique_years) {
# Subset the data for the current year
year_data = data[data$year == year, ]
# Match the `ano_91.20` values to the display dates using the keys
merged_data = merge(data.frame(
display_key = display_keys,
display_date = display_dates
),
data.frame(display_key = year_data$key, ano_91.20 = year_data$ano_91.20), by = "display_key", all.x = TRUE)
# Add the column to the result, named by the year
result[[year]] = merged_data$ano_91.20
}
result
# Print the result
print(head(result, 15))  # Show the first 15 rows for demonstration
output_file = file.path(output_dir, "daily_global_anomalies.csv")
# save the data
output_dir = "output/daily_global_anomaly"
# save the data
output_dir = "output/daily_global_anomaly"
# save the data
output_dir = file.path("output/daily_global_anomaly")
output_dir
# save the data
output_dir = file.path("output/daily_global_anomaly")
if(!dir.exists(output_dir)){
dir.create(output_dir, recursive = T)
}
output_file = file.path(output_dir, "daily_global_anomalies.csv")
output_file
write.csv(result, output_file)
library(DatawRappr)
dw_retrieve_chart_metadata("TJGRP")
m = dw_retrieve_chart_metadata("TJGRP")
m$content$title
dw_retrieve_chart_metadata("TJGRP")
m = dw_retrieve_chart_metadata("TJGRP")
m$content$metadata
m$content$metadata$describe
m = dw_retrieve_chart_metadata("TJGRP")
m$content$metadata$describe
m$content$metadata$custom
m$content$metadata$annotate
# URLs and model names
urls = list(
list(
url = "https://climate.metoffice.cloud/formatted_data/gmt_HadCRUT5.csv",
name = "HadCRUT5"
),
list(
url = "https://climate.metoffice.cloud/formatted_data/gmt_NOAAGlobalTemp.csv",
name = "NOAAGlobalTemp"
),
list(
url = "https://climate.metoffice.cloud/formatted_data/gmt_GISTEMP.csv",
name = "GISTEMP"
),
list(
url = "https://climate.metoffice.cloud/formatted_data/gmt_ERA5.csv",
name = "ERA5"
),
list(
url = "https://climate.metoffice.cloud/formatted_data/gmt_JRA-55.csv",
name = "JRA-55"
),
list(
url = "https://climate.metoffice.cloud/formatted_data/gmt_Berkeley%20Earth.csv",
name = "BerkeleyEarth"
)
)
# Function to read and process the data
read_and_process = function(url, name) {
data = read.csv(url)
# Assuming the temperature data is in the second column
model_column_name = names(data)[2]  # Adjust this if necessary
# Return a data frame with YEAR and the model data
return(data.frame(Year=data$Year, model_data = data[[model_column_name]]))
}
# Read data from each URL and process
all_data = lapply(urls, function(x) {
read_and_process(x$url, x$name)
})
all_data
# Merge all data frames by the YEAR column
merged_data = all_data[[1]]
for (i in 2:length(all_data)) {
merged_data = merge(merged_data, all_data[[i]], by = "Year", all = TRUE)
}
merged_data
merged_data %>% head
head(merged_data)
# Rename columns based on the model names
names(merged_data)[-1] = sapply(urls, function(x) x$name)
head(merged_data)
# Save the final result
output_dir = "output/merged_data"
if (!dir.exists(output_dir)) {
dir.create(output_dir, recursive = TRUE)
}
# Output file path
output_file = file.path(output_dir, "merged_models_data.csv")
write.csv(merged_data, output_file, row.names = FALSE)
